{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.seed()\n",
    "rand.randint(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#small_df = pd.read_csv('CS205_small_testdata__3.txt', sep=\"  \",header=None)\n",
    "#large_df = pd.read_csv('CS205_large_testdata__36.txt', sep=\"  \",header=None)\n",
    "\n",
    "small = np.loadtxt(\"CS205_small_testdata__3.txt\")\n",
    "large= np.loadtxt('CS205_large_testdata__36.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a testing stub to make sure that the search is working correctly\n",
    "def acc_class(ftr):\n",
    "    return(rand.randint(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_class(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,len(small[1,:])): print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ftr_search(mat):\n",
    "    # List to keep track of all the current features\n",
    "    crnt_ftr = []\n",
    "    levels_best = []\n",
    "    \n",
    "    # Each level of the search tree\n",
    "    for i in range(1,len(mat[1,:])):\n",
    "        # List to keep track of the added feature\n",
    "        add_ftr = -1\n",
    "        # Keeps track of the best accuracy\n",
    "        best_acc = -1\n",
    "        print(\"On the\", i, \"th level of the search tree\")\n",
    "        \n",
    "        # At each level, we want to see which features we can add\n",
    "        for j in range(1,len(mat[1,:])):\n",
    "            #print(j)\n",
    "            #print(crnt_ftr)\n",
    "            # At each level, I want to test the accuracy of adding a certain feature\n",
    "            # but I don't want to consider a feature that's already included\n",
    "            if j not in crnt_ftr:\n",
    "                print(\"  Considering adding the \", j, \"feature\")\n",
    "                # Calculate the accuracy for the given set of features\n",
    "                acc = knn(mat, crnt_ftr, j)\n",
    "                #acc = acc_class(j)\n",
    "                # Checking if we should add this feature based on how it compares\n",
    "                # to the best accuracy so far.\n",
    "                #print(best_acc,acc)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    add_ftr = j # This is always updated when the accuracy is better.\n",
    "                #print(add_ftr)\n",
    "                \n",
    "        # After we check all the features that we can add at this level\n",
    "        # we want to make the current feature set is updated based on the best feature   \n",
    "        crnt_ftr.append(add_ftr) \n",
    "        # The best combination of features and its accuracy at the current level\n",
    "        levels_best.append((best_acc,crnt_ftr[:]))  # [:] is a copy of what is in the list now\n",
    "        #print(add_ftr)\n",
    "        print(\"*On level \", i, \"added feature\", add_ftr, \"to current set*\")\n",
    "        #print(crnt_ftr)\n",
    "        #print(crnt_ftr)\n",
    "        #print(len(set(crnt_ftr)))\n",
    "    return(levels_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a function that will perform kNN\n",
    "def knn(mat, crnt_set_, new_ftr):\n",
    "    '''\n",
    "    '''\n",
    "    # Keep track of accuracy\n",
    "    acc = 0\n",
    "    # The features that will be used for classification\n",
    "    crnt_set = crnt_set_[:]\n",
    "    crnt_set.append(new_ftr)\n",
    "    #print(crnt_set)\n",
    "  \n",
    "    # Leave one out cross validation for each of the observations\n",
    "    # with K = 1 nearest neighbors\n",
    "    for i in range(0,len(mat)):\n",
    "        # The observation to classify\n",
    "        obs = mat[i,crnt_set]\n",
    "        obs_label = mat[i,0]\n",
    "        # An initial value for the distance that will be updated\n",
    "        # if the distance at some iteration is smaller than the previous \n",
    "        # smallest distance.\n",
    "        nn_dist = 1000000\n",
    "        # Variable to keep track of the index that's closest to obs.\n",
    "        nn_ind = 0\n",
    "        # Now we compare each observation to the rest\n",
    "        for j in range(0,len(mat)):\n",
    "            # A check to make sure that the function is working properly\n",
    "            # print(\"Ask if\", i, \"is nearest neighbor with\", j)\n",
    "            if j != i: # don't compare observation to itself\n",
    "                #print(len(obs),len(mat[j,crnt_set]))\n",
    "                #print(obs, mat[j,crnt_set])\n",
    "                dist = math.sqrt(sum(obs-mat[j,crnt_set])**2)\n",
    "                #print(dist,nn_dist)\n",
    "                if dist < nn_dist: # update label if this is true\n",
    "                    nn_dist = dist\n",
    "                    nn_ind = j\n",
    "                    label = mat[j,0] # the label of the closest observation\n",
    "                    \n",
    "        # After finding the best label, check whether it was classified correctly\n",
    "        if label == obs_label:\n",
    "            acc = acc + 1\n",
    "            \n",
    "    acc_rate = acc/len(mat)\n",
    "    return(acc_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the 1 th level of the search tree\n",
      "  Considering adding the  1 feature\n",
      "  Considering adding the  2 feature\n",
      "  Considering adding the  3 feature\n",
      "  Considering adding the  4 feature\n",
      "  Considering adding the  5 feature\n",
      "  Considering adding the  6 feature\n",
      "  Considering adding the  7 feature\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  9 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  1 added feature 4 to current set*\n",
      "On the 2 th level of the search tree\n",
      "  Considering adding the  1 feature\n",
      "  Considering adding the  2 feature\n",
      "  Considering adding the  3 feature\n",
      "  Considering adding the  5 feature\n",
      "  Considering adding the  6 feature\n",
      "  Considering adding the  7 feature\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  9 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  2 added feature 1 to current set*\n",
      "On the 3 th level of the search tree\n",
      "  Considering adding the  2 feature\n",
      "  Considering adding the  3 feature\n",
      "  Considering adding the  5 feature\n",
      "  Considering adding the  6 feature\n",
      "  Considering adding the  7 feature\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  9 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  3 added feature 5 to current set*\n",
      "On the 4 th level of the search tree\n",
      "  Considering adding the  2 feature\n",
      "  Considering adding the  3 feature\n",
      "  Considering adding the  6 feature\n",
      "  Considering adding the  7 feature\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  9 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  4 added feature 9 to current set*\n",
      "On the 5 th level of the search tree\n",
      "  Considering adding the  2 feature\n",
      "  Considering adding the  3 feature\n",
      "  Considering adding the  6 feature\n",
      "  Considering adding the  7 feature\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  5 added feature 3 to current set*\n",
      "On the 6 th level of the search tree\n",
      "  Considering adding the  2 feature\n",
      "  Considering adding the  6 feature\n",
      "  Considering adding the  7 feature\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  6 added feature 2 to current set*\n",
      "On the 7 th level of the search tree\n",
      "  Considering adding the  6 feature\n",
      "  Considering adding the  7 feature\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  7 added feature 6 to current set*\n",
      "On the 8 th level of the search tree\n",
      "  Considering adding the  7 feature\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  8 added feature 7 to current set*\n",
      "On the 9 th level of the search tree\n",
      "  Considering adding the  8 feature\n",
      "  Considering adding the  10 feature\n",
      "*On level  9 added feature 8 to current set*\n",
      "On the 10 th level of the search tree\n",
      "  Considering adding the  10 feature\n",
      "*On level  10 added feature 10 to current set*\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.84, [4]),\n",
       " (0.74, [4, 1]),\n",
       " (0.75, [4, 1, 5]),\n",
       " (0.76, [4, 1, 5, 9]),\n",
       " (0.7466666666666667, [4, 1, 5, 9, 3]),\n",
       " (0.7366666666666667, [4, 1, 5, 9, 3, 2]),\n",
       " (0.71, [4, 1, 5, 9, 3, 2, 6]),\n",
       " (0.7166666666666667, [4, 1, 5, 9, 3, 2, 6, 7]),\n",
       " (0.7, [4, 1, 5, 9, 3, 2, 6, 7, 8]),\n",
       " (0.7133333333333334, [4, 1, 5, 9, 3, 2, 6, 7, 8, 10])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the ftr_search function with the small dataset\n",
    "ftr_search(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622832115.594087\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(start_time)\n",
    "# Testing the ftr_search function with the large dataset\n",
    "#ftr_search(large)\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(40, [4]), (42, [4, 6]), (38, [4, 6, 3]), (50, [4, 6, 3, 5]), (36, [4, 6, 3, 5, 0]), (40, [4, 6, 3, 5, 0, 1]), (46, [4, 6, 3, 5, 0, 1, 2]), (44, [4, 6, 3, 5, 0, 1, 2, 9]), (39, [4, 6, 3, 5, 0, 1, 2, 9, 8]), (11, [4, 6, 3, 5, 0, 1, 2, 9, 8, 10]), (28, [4, 6, 3, 5, 0, 1, 2, 9, 8, 10, 7])]\n",
      "[(11, [4, 6, 3, 5, 0, 1, 2, 9, 8, 10]), (28, [4, 6, 3, 5, 0, 1, 2, 9, 8, 10, 7]), (36, [4, 6, 3, 5, 0]), (38, [4, 6, 3]), (39, [4, 6, 3, 5, 0, 1, 2, 9, 8]), (40, [4]), (40, [4, 6, 3, 5, 0, 1]), (42, [4, 6]), (44, [4, 6, 3, 5, 0, 1, 2, 9]), (46, [4, 6, 3, 5, 0, 1, 2]), (50, [4, 6, 3, 5])]\n"
     ]
    }
   ],
   "source": [
    "print(combs)\n",
    "combs.sort()   # Sort by the first element in the tuple first\n",
    "print(combs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7133333333333334"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the kNN \\function on the small dataset with all featuers\n",
    "knn(mat = small, crnt_set, new_ftr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(sum(small[1,1:]-small[2,1:]))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.456618812189467"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(small[1,[1,2]]-small[2,[1,2]])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02937927,  0.75751174, -0.57226014])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small[1,[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-126c18dc7738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "len(small[1,-0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small[1,-0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-6a9232486a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "l.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for j in range(,5): print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
